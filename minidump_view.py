# minidump_view.py
# a binaryview plugin for loading windows minidump files in binary ninja.
# this plugin uses a kaitai struct generated parser for the minidump format.

import io
import traceback  # for detailed error logging

# binary ninja api imports
from binaryninja import (
    BinaryView,
    SegmentFlag,
    SectionSemantics,
    Symbol,
    SymbolType,
    Platform,
    Architecture,
    Endianness,
    TagType,  # Added for creating custom tags
    Logger,
)

# --- kaitai struct integration ---
# the user must ensure 'kaitaistruct' is installed in binary ninja's python environment
# and that 'windows_minidump.py' (generated by kaitai struct compiler) is in this plugin's directory.
try:
    from kaitaistruct import KaitaiStream, BytesIO

    # this is the assumed name of the kaitai-generated parser module.
    # please adjust if your generated file has a different name.
    # ensure this can be found, e.g., by placing windows_minidump.py in the same directory
    from .windows_minidump import WindowsMinidump
except ImportError as e:
    print(
        f"[MinidumpLoader] Error: Kaitai Struct runtime or Minidump parser not found: {e}"
    )
    print("[MinidumpLoader] Please install kaitaistruct (`pip install kaitaistruct`)")
    print(
        "[MinidumpLoader] and ensure 'windows_minidump.py' is in the plugin directory."
    )
    raise


class MinidumpView(BinaryView):
    """
    a custom binaryview for interpreting windows minidump files.
    it parses the minidump structure, maps memory segments, identifies modules,
    and sets up the binary ninja environment for analysis with rich annotations.
    """

    name = "Minidump (Kaitai)"
    long_name = "Windows Minidump File (Kaitai)"

    # tag type for marking the crash site
    CRASH_TAG_TYPE_NAME = "Crash Site"
    CRASH_TAG_ICON = "ðŸ’¥"

    def __init__(self, data: BinaryView):
        """
        initializes the minidumpview instance.
        args:
            data: the parent binaryview, which provides access to the raw file data.
        """
        super().__init__(file_metadata=data.file, parent_view=data)
        self.raw_data: BinaryView = data
        self.log: Logger = self.create_logger("Minidump")

        self.dmp: WindowsMinidump | None = None
        self._address_size: int = 8
        self._endianness: Endianness = Endianness.LittleEndian
        self._platform: Platform | None = None
        self._arch: Architecture | None = None

        self._parsed_streams: dict = {}
        self._memory_protections: dict = {}  # va_start -> minidump_protection_enum
        self._crash_tag_type: TagType | None = None

        # for perform_get_start / perform_get_length
        self._min_virtual_address: int = 0xFFFFFFFFFFFFFFFF
        self._max_virtual_address: int = 0

    def init(self) -> bool:
        """
        main initialization and parsing method.
        returns:
            true if initialization is successful, false otherwise.
        """
        self.log.log_info("Starting Minidump initialization...")

        if not self._parse_minidump_with_kaitai():
            return False

        if not self._extract_header_info():
            return False

        self._cache_parsed_streams()

        # create tag types used by this loader
        self._crash_tag_type = self._get_or_create_tag_type(
            self.CRASH_TAG_TYPE_NAME, self.CRASH_TAG_ICON
        )

        # process streams that provide foundational info first
        self._process_system_info_stream(
            self._parsed_streams.get(WindowsMinidump.StreamTypeEnum.system_info_stream)
        )
        self._process_memory_info_list_stream(
            self._parsed_streams.get(
                WindowsMinidump.StreamTypeEnum.memory_info_list_stream
            )
        )

        # process streams that define memory layout and modules
        self._process_memory_segments()  # handles both memory64list and memorylist
        self._process_module_list_stream(
            self._parsed_streams.get(WindowsMinidump.StreamTypeEnum.module_list_stream)
        )
        self._process_unloaded_module_list_stream(
            self._parsed_streams.get(
                WindowsMinidump.StreamTypeEnum.unloaded_module_list_stream
            )
        )

        # process streams with runtime state information
        self._process_thread_list_stream(
            self._parsed_streams.get(WindowsMinidump.StreamTypeEnum.thread_list_stream)
        )
        self._process_exception_stream(
            self._parsed_streams.get(WindowsMinidump.StreamTypeEnum.exception_stream)
        )
        self._process_handle_data_stream(
            self._parsed_streams.get(WindowsMinidump.StreamTypeEnum.handle_data_stream)
        )
        self._process_misc_info_stream(
            self._parsed_streams.get(WindowsMinidump.StreamTypeEnum.misc_info_stream)
        )
        # todo: process other streams like CommentStream, ThreadInfoListStream, etc.

        self._finalize_view_setup()

        self.log.log_info("Minidump initialization complete.")
        return True

    def _parse_minidump_with_kaitai(self) -> bool:
        """reads the raw file and parses it using the kaitai struct generated parser."""
        self.log.log_debug("Reading raw file data for Kaitai parsing...")
        try:
            file_bytes = self.raw_data.read(0, self.raw_data.length)
            kaitai_stream = KaitaiStream(BytesIO(file_bytes))
            self.dmp = WindowsMinidump(kaitai_stream)
            self.log.log_info("Kaitai Struct parsing successful.")
            return True
        except Exception as e:
            self.log.log_error(f"Kaitai Struct parsing failed: {e}")
            self.log.log_error(traceback.format_exc())
            return False

    def _extract_header_info(self) -> bool:
        """validates and extracts basic information from the parsed minidump header."""
        if not self.dmp or not self.dmp.header:
            self.log.log_error("Kaitai parser did not produce a valid header object.")
            return False

        header = self.dmp.header
        # verify signature (kaitai enum name might differ, e.g., WindowsMinidump.Magic.mdmp)
        # IMPORTANT: Adjust `WindowsMinidump.MagicSignature.minidump` to your actual Kaitai enum.
        if header.signature != WindowsMinidump.MagicSignature.minidump:
            self.log.log_error(
                f"Invalid minidump signature after full parse. Expected "
                f"'{WindowsMinidump.MagicSignature.minidump!r}', got '{header.signature!r}'."
            )
            return False

        num_streams = header.num_streams
        minidump_flags = header.flags  # type: ignore
        self.log.log_info(
            f"Minidump contains {num_streams} streams. Flags: {minidump_flags!r}"
        )
        return True

    def _cache_parsed_streams(self):
        """iterates through the kaitai parsed stream directory and caches stream data by type."""
        if not self.dmp or not self.dmp.dir_streams:
            self.log.log_warn("Minidump stream directory is empty or not parsed.")
            return

        self.log.log_debug(f"Caching {len(self.dmp.dir_streams)} streams...")
        for stream_dir_entry in self.dmp.dir_streams:
            # IMPORTANT: `stream_dir_entry.body` is an assumption for where Kaitai places
            # the parsed stream data. Verify with your `windows_minidump.py`.
            # It might be `stream_dir_entry.data` or another attribute name.
            if hasattr(stream_dir_entry, "body"):
                self._parsed_streams[stream_dir_entry.stream_type] = (
                    stream_dir_entry.body
                )
                self.log.log_debug(f"  Cached stream: {stream_dir_entry.stream_type!r}")
            else:
                self.log.log_warn(
                    f"Stream entry for type {stream_dir_entry.stream_type!r} has no 'body' attribute. Kaitai structure might differ."
                )

    def _process_system_info_stream(self, sys_info_data) -> None:
        """processes the systeminfo stream to set platform and architecture."""
        if not sys_info_data:
            self.log.log_warn(
                "SystemInfoStream not found. Using default platform settings (may be incorrect)."
            )
            return

        self.log.log_debug("Processing SystemInfoStream...")
        arch_str, os_str = self._map_system_info_to_platform(sys_info_data)
        if arch_str and os_str:
            try:
                self._platform = Platform[f"{os_str}-{arch_str}"]
                self._arch = self._platform.arch
                self._address_size = (
                    self._arch.address_size
                    if self._arch
                    else (8 if "64" in arch_str or arch_str == "aarch64" else 4)
                )
                self.platform = self._platform  # assign to the binaryview's platform
                self.log.log_info(
                    f"Platform set to '{self._platform.name}'. Address Size: {self._address_size} bytes."
                )
            except KeyError:
                self.log.log_error(
                    f"Binary Ninja does not support platform '{os_str}-{arch_str}'. Cannot proceed with this platform."
                )
                # consider setting a fallback or raising an error to stop loading
        else:
            self.log.log_warn(
                "Could not determine platform from SystemInfoStream. Analysis may be impaired."
            )

    def _process_memory_info_list_stream(self, mem_info_list_data) -> None:
        """processes the memoryinfolist stream to cache memory region protections."""
        if not mem_info_list_data:
            self.log.log_warn(
                "MemoryInfoListStream not found. Segment permissions may be inaccurate."
            )
            return

        self.log.log_debug("Processing MemoryInfoListStream...")
        # IMPORTANT: Verify `mem_info_list_data.infos` with your Kaitai parser.
        if hasattr(mem_info_list_data, "infos"):
            for mem_info in mem_info_list_data.infos:
                # IMPORTANT: Verify `mem_info.base_address` and `mem_info.protect`.
                self._memory_protections[mem_info.base_address] = mem_info.protect
            self.log.log_info(
                f"Processed and cached {len(self._memory_protections)} memory info entries."
            )
        else:
            self.log.log_warn(
                "MemoryInfoListStream data does not have 'infos' attribute. Kaitai structure might differ."
            )

    def _process_memory_segments(self) -> None:
        """processes memory64liststream or memoryliststream to map memory segments."""
        mem64_list_data = self._parsed_streams.get(
            WindowsMinidump.StreamTypeEnum.memory64_list_stream
        )
        mem_list_data = self._parsed_streams.get(
            WindowsMinidump.StreamTypeEnum.memory_list_stream
        )

        if mem64_list_data:
            self.log.log_debug("Processing Memory64ListStream...")
            # IMPORTANT: Verify `mem64_list_data.base_rva` and `mem64_list_data.mem_ranges`.
            base_rva_for_data = mem64_list_data.base_rva
            current_file_offset_for_data = base_rva_for_data
            self.log.log_info(
                f"Memory64ListStream BaseRVA for data: 0x{base_rva_for_data:x}"
            )
            if hasattr(mem64_list_data, "mem_ranges"):
                for mem_desc in mem64_list_data.mem_ranges:
                    # IMPORTANT: Verify `mem_desc.start_of_memory_range` and `mem_desc.data_size`.
                    va = mem_desc.start_of_memory_range
                    size = mem_desc.data_size
                    if size == 0:
                        self.log.log_debug(
                            f"  Skipping zero-size memory descriptor at VA 0x{va:x}."
                        )
                        continue

                    self._min_virtual_address = min(self._min_virtual_address, va)
                    self._max_virtual_address = max(
                        self._max_virtual_address, va + size
                    )

                    protection_enum = self._memory_protections.get(va)
                    r, w, x = self._translate_memory_protection(protection_enum)

                    seg_flags = SegmentFlag(0)
                    if r:
                        seg_flags |= SegmentFlag.SegmentReadable
                    if w:
                        seg_flags |= SegmentFlag.SegmentWritable
                    if x:
                        seg_flags |= SegmentFlag.SegmentExecutable

                    self.log.log_info(
                        f"  Adding segment: VA=0x{va:0{self._address_size*2}x}, Size=0x{size:x}, FileOffset=0x{current_file_offset_for_data:x}, Flags={seg_flags!r}"
                    )
                    self.add_auto_segment(
                        va, size, current_file_offset_for_data, size, seg_flags
                    )
                    self.set_comment_at(
                        va,
                        f"Minidump Memory Segment. Original Protection: {str(protection_enum) if protection_enum else 'Unknown'}",
                    )
                    current_file_offset_for_data += size
            else:
                self.log.log_warn(
                    "Memory64ListStream data does not have 'mem_ranges' attribute. Kaitai structure might differ."
                )

        elif mem_list_data:
            self.log.log_debug("Processing MemoryListStream (32-bit)...")
            # IMPORTANT: Verify `mem_list_data.mem_ranges`.
            if hasattr(mem_list_data, "mem_ranges"):
                for mem_desc in mem_list_data.mem_ranges:
                    # IMPORTANT: Verify Kaitai names: `mem_desc.start_of_memory_range`,
                    # `mem_desc.memory.rva`, `mem_desc.memory.data_size`.
                    va = mem_desc.start_of_memory_range
                    file_offset_in_dump = mem_desc.memory.rva
                    size = mem_desc.memory.data_size
                    if size == 0:
                        self.log.log_debug(
                            f"  Skipping zero-size memory descriptor at VA 0x{va:x}."
                        )
                        continue

                    self._min_virtual_address = min(self._min_virtual_address, va)
                    self._max_virtual_address = max(
                        self._max_virtual_address, va + size
                    )

                    protection_enum = self._memory_protections.get(va)
                    r, w, x = self._translate_memory_protection(protection_enum)

                    seg_flags = SegmentFlag(0)
                    if r:
                        seg_flags |= SegmentFlag.SegmentReadable
                    if w:
                        seg_flags |= SegmentFlag.SegmentWritable
                    if x:
                        seg_flags |= SegmentFlag.SegmentExecutable

                    self.log.log_info(
                        f"  Adding segment: VA=0x{va:0{self._address_size*2}x}, Size=0x{size:x}, FileOffset=0x{file_offset_in_dump:x}, Flags={seg_flags!r}"
                    )
                    self.add_auto_segment(
                        va, size, file_offset_in_dump, size, seg_flags
                    )
                    self.set_comment_at(
                        va,
                        f"Minidump Memory Segment. Original Protection: {str(protection_enum) if protection_enum else 'Unknown'}",
                    )
            else:
                self.log.log_warn(
                    "MemoryListStream data does not have 'mem_ranges' attribute. Kaitai structure might differ."
                )
        else:
            self.log.log_warn(
                "No memory list stream found (Memory64ListStream or MemoryListStream). Memory map will be incomplete."
            )

    def _process_module_list_stream(self, module_list_data) -> None:
        """processes the modulelist stream to define sections and symbols for loaded modules."""
        if not module_list_data:
            self.log.log_warn("ModuleListStream not found. No modules will be defined.")
            return

        # IMPORTANT: Verify `module_list_data.modules`.
        if not hasattr(module_list_data, "modules"):
            self.log.log_warn(
                "ModuleListStream data does not have 'modules' attribute. Kaitai structure might differ."
            )
            return

        self.log.log_info(
            f"Processing {len(module_list_data.modules)} modules from ModuleListStream."
        )
        for mod_info in module_list_data.modules:
            # IMPORTANT: Verify Kaitai names: `mod_info.module_name.name`,
            # `mod_info.base_of_image`, `mod_info.size_of_image`.
            try:
                # `module_name` is typically a MINIDUMP_STRING structure in Kaitai.
                # It should have an attribute like `name` or `str_` for the actual string.
                name = mod_info.module_name.name
            except AttributeError:
                self.log.log_warn(
                    f"Could not get module name for module at base 0x{mod_info.base_of_image:x}. Kaitai structure for MinidumpString might differ. Defaulting name."
                )
                name = f"UnknownModule_0x{mod_info.base_of_image:x}"

            base_va = mod_info.base_of_image
            size = mod_info.size_of_image

            self.log.log_info(
                f"  Adding module: {name}, BaseVA=0x{base_va:0{self._address_size*2}x}, Size=0x{size:x}"
            )
            self.add_auto_section(
                name, base_va, size, SectionSemantics.ReadOnlyCodeSectionSemantics
            )  # Default, can be refined
            self.define_auto_symbol(Symbol(SymbolType.LibrarySymbol, base_va, name))
            self.set_comment_at(
                base_va,
                f"Module: {name}\nTimestamp: {mod_info.time_date_stamp_as_datetime if hasattr(mod_info, 'time_date_stamp_as_datetime') else mod_info.time_date_stamp}\nChecksum: 0x{mod_info.checksum:x}",
            )

    def _process_thread_list_stream(self, thread_list_data) -> None:
        """processes the threadlist stream for thread information, stacks, and contexts."""
        if not thread_list_data:
            self.log.log_warn("ThreadListStream not found.")
            return

        # IMPORTANT: Verify `thread_list_data.threads`.
        if not hasattr(thread_list_data, "threads"):
            self.log.log_warn(
                "ThreadListStream data does not have 'threads' attribute. Kaitai structure might differ."
            )
            return

        self.log.log_info(
            f"Processing {len(thread_list_data.threads)} threads from ThreadListStream."
        )
        for i, thread in enumerate(thread_list_data.threads):
            # IMPORTANT: Verify Kaitai names like `thread.thread_id`, `thread.stack.start_of_memory_range`,
            # `thread.thread_context_actual.program_counter` (or similar for register access).
            tid = thread.thread_id
            stack_va = thread.stack.start_of_memory_range
            stack_size = (
                thread.stack.memory.data_size
            )  # Assuming this field exists for stack data size
            teb = thread.teb

            self.log.log_info(
                f"  Thread ID: {tid}, Stack Start: 0x{stack_va:x}, Stack Size: 0x{stack_size:x}, TEB: 0x{teb:x}"
            )
            self.set_comment_at(
                stack_va, f"Thread {tid} Stack (Size: 0x{stack_size:x})"
            )

            # process thread context for registers
            # the actual context structure (e.g., `thread.thread_context_actual`) and register names
            # will heavily depend on the Kaitai .ksy definition for MINIDUMP_CONTEXT.
            # this is a placeholder and needs to be adapted.
            if (
                hasattr(thread, "thread_context_actual")
                and thread.thread_context_actual
            ):
                context = thread.thread_context_actual
                # example for x86_64, names will vary based on .ksy
                ip_reg_name = None
                if self._arch and self._arch.name == "x86_64":
                    ip_reg_name = "rip"
                elif self._arch and self._arch.name == "x86":
                    ip_reg_name = "eip"
                elif self._arch and self._arch.name == "aarch64":
                    ip_reg_name = "pc"  # Or x30 if LR is PC
                # Add more architectures

                if ip_reg_name and hasattr(context, ip_reg_name):
                    ip = getattr(context, ip_reg_name)
                    self.log.log_info(
                        f"    Thread {tid} Instruction Pointer ({ip_reg_name.upper()}): 0x{ip:x}"
                    )
                    self.define_auto_symbol(
                        Symbol(
                            SymbolType.CodeSymbol,
                            ip,
                            f"Thread_{tid}_{ip_reg_name.upper()}",
                        )
                    )
                    self.set_comment_at(
                        ip, f"Thread {tid} Instruction Pointer at time of dump."
                    )
                else:
                    self.log.log_warn(
                        f"    Thread {tid}: Could not determine instruction pointer register name or value from context."
                    )
                # Log other key registers if available and relevant
            else:
                self.log.log_warn(
                    f"    Thread {tid}: No detailed context information found or 'thread_context_actual' missing."
                )

    def _process_exception_stream(self, exception_data) -> None:
        """processes the exception stream if present."""
        if not exception_data:
            self.log.log_debug(
                "No ExceptionStream found."
            )  # Not an error, dump might not be from a crash
            return

        # IMPORTANT: Verify Kaitai names like `exception_data.thread_id`,
        # `exception_data.exception_record_actual.exception_address`, `.exception_code`, etc.
        self.log.log_info("Processing ExceptionStream...")
        try:
            thread_id = exception_data.thread_id
            record = (
                exception_data.exception_record_actual
            )  # Assuming Kaitai parses the record here
            exc_addr = record.exception_address
            exc_code = record.exception_code  # This will be an enum
            exc_flags = record.flags  # This will be an enum

            self.log.log_warn(f"  Exception occurred in Thread ID: {thread_id}")
            self.log.log_warn(
                f"  Exception Code: {exc_code!r} ({self._get_exception_code_string(exc_code)})"
            )
            self.log.log_warn(f"  Exception Flags: {exc_flags!r}")
            self.log.log_warn(
                f"  Exception Address: 0x{exc_addr:0{self._address_size*2}x}"
            )

            comment = (
                f"Minidump Exception Site\n"
                f"Thread ID: {thread_id}\n"
                f"Exception Code: {exc_code!r} ({self._get_exception_code_string(exc_code)})\n"
                f"Faulting Address: 0x{exc_addr:0{self._address_size*2}x}"
            )
            if (
                hasattr(record, "exception_information")
                and record.exception_information
            ):
                comment += f"\n  Parameters: {record.exception_information}"

            self.set_comment_at(exc_addr, comment)
            if self._crash_tag_type:
                self.add_tag(
                    exc_addr,
                    self._crash_tag_type,
                    "Minidump crash site reported by ExceptionStream.",
                )

            # attempt to set entry point to the crash site for quick navigation
            self.log.log_info(
                f"Setting entry point to exception address 0x{exc_addr:x}"
            )
            self.add_entry_point(exc_addr)

        except AttributeError as e:
            self.log.log_error(
                f"Error accessing attributes in ExceptionStream data (Kaitai structure might differ): {e}"
            )
        except Exception as e:
            self.log.log_error(f"Unexpected error processing ExceptionStream: {e}")
            self.log.log_error(traceback.format_exc())

    def _get_exception_code_string(self, exc_code_enum) -> str:
        """Helper to get a string representation of an exception code enum."""
        # This is highly dependent on your Kaitai enum definition for exception codes.
        # Example: if exc_code_enum is WindowsMinidump.ExceptionCodeEnum.access_violation
        if hasattr(
            exc_code_enum, "name"
        ):  # Kaitai enums usually have a 'name' attribute
            return exc_code_enum.name
        return str(exc_code_enum)  # Fallback to raw enum value

    def _process_unloaded_module_list_stream(self, unloaded_module_data) -> None:
        if not unloaded_module_data:
            self.log.log_debug("No UnloadedModuleListStream found.")
            return
        # IMPORTANT: Verify `unloaded_module_data.modules`.
        if not hasattr(unloaded_module_data, "modules"):
            self.log.log_warn(
                "UnloadedModuleListStream data does not have 'modules' attribute. Kaitai structure might differ."
            )
            return

        self.log.log_info(
            f"Processing {len(unloaded_module_data.modules)} unloaded modules."
        )
        for mod_info in unloaded_module_data.modules:
            # IMPORTANT: Verify Kaitai names.
            try:
                name = mod_info.module_name.name
                base = mod_info.base_of_image
                size = mod_info.size_of_image
                self.log.log_info(
                    f"  Unloaded Module: {name}, Base: 0x{base:x}, Size: 0x{size:x}"
                )
                # could add comments or non-mapped sections if desired, but they are unloaded.
            except AttributeError:
                self.log.log_warn(
                    f"Could not fully parse unloaded module entry. Kaitai structure might differ."
                )

    def _process_handle_data_stream(self, handle_data) -> None:
        if not handle_data:
            self.log.log_debug("No HandleDataStream found.")
            return
        # IMPORTANT: Verify `handle_data.handles`.
        if not hasattr(handle_data, "handles"):
            self.log.log_warn(
                "HandleDataStream data does not have 'handles' attribute. Kaitai structure might differ."
            )
            return

        self.log.log_info(f"Processing {len(handle_data.handles)} handles.")
        for i, handle_desc in enumerate(handle_data.handles):
            # IMPORTANT: Verify Kaitai names for handle attributes.
            try:
                obj_name_rva = (
                    handle_desc.object_name_rva
                )  # This is an RVA into the minidump file
                type_name_rva = handle_desc.type_name_rva  # This is an RVA
                # To get actual names, you'd need to read these RVAs from self.raw_data
                # and parse the MINIDUMP_STRING structures there. Kaitai might not do this automatically
                # if the .ksy defines them just as RVAs.
                # For now, just log the RVAs.
                self.log.log_debug(
                    f"  Handle {i}: HandleValue=0x{handle_desc.handle:x}, TypeNameRVA=0x{type_name_rva:x}, ObjectNameRVA=0x{obj_name_rva:x}, Attributes=0x{handle_desc.attributes:x}"
                )
            except AttributeError:
                self.log.log_warn(
                    f"Could not fully parse handle entry {i}. Kaitai structure might differ."
                )

    def _process_misc_info_stream(self, misc_info_data) -> None:
        if not misc_info_data:
            self.log.log_debug("No MiscInfoStream found.")
            return

        self.log.log_info("Processing MiscInfoStream...")
        # IMPORTANT: Verify Kaitai names like `misc_info_data.process_id`, `misc_info_data.process_create_time_as_datetime`.
        try:
            pid = (
                misc_info_data.process_id
                if hasattr(misc_info_data, "process_id")
                else "N/A"
            )
            create_time = (
                misc_info_data.process_create_time_as_datetime
                if hasattr(misc_info_data, "process_create_time_as_datetime")
                else misc_info_data.process_create_time
            )
            self.log.log_info(f"  Process ID: {pid}")
            self.log.log_info(f"  Process Create Time: {create_time}")
            # Add more fields as needed (user time, kernel time, processor info)
        except AttributeError:
            self.log.log_warn(
                "Could not fully parse MiscInfoStream. Kaitai structure might differ."
            )

    def _finalize_view_setup(self) -> None:
        """final setup steps after all core streams are processed."""
        # if no specific entry point was set (e.g., from exception), default to start or 0.
        if not self.entry_points:
            entry_candidate = (
                self._min_virtual_address
                if self._min_virtual_address != 0xFFFFFFFFFFFFFFFF
                else 0
            )
            self.log.log_info(
                f"No explicit entry point set, defaulting to 0x{entry_candidate:x} (min VA or 0)."
            )
            self.add_entry_point(entry_candidate)

        # Consider triggering an initial analysis update if desired,
        # though often it's better to let the user do this.
        # self.update_analysis_and_wait()

    def _get_or_create_tag_type(self, name: str, icon: str) -> TagType | None:
        """gets an existing tag type or creates it if it doesn't exist."""
        try:
            tag_type = self.get_tag_type(name)
            if tag_type:
                self.log.log_debug(f"Found existing TagType '{name}'.")
                return tag_type
        except KeyError:  # BN may raise KeyError if not found
            pass
        except Exception as e:  # Catch other potential issues
            self.log.log_warn(f"Error checking for existing TagType '{name}': {e}")

        try:
            self.log.log_info(f"Creating new TagType '{name}' with icon '{icon}'.")
            return self.create_tag_type(name, icon)
        except (
            Exception
        ) as e:  # Catch errors during creation (e.g., already exists by different case)
            self.log.log_error(
                f"Failed to create TagType '{name}': {e}. Trying to get it again."
            )
            # It might have been created by another part or with different casing, try getting it again.
            try:
                return self.get_tag_type(name)
            except Exception:
                self.log.log_error(
                    f"Still could not get TagType '{name}' after creation attempt."
                )
                return None

    # --- required binaryview method implementations ---

    def perform_get_address_size(self) -> int:
        return self._address_size

    def perform_get_default_endianness(self) -> Endianness:
        return self._endianness

    def perform_get_entry_point(self) -> int:
        if self.entry_points:  # self.entry_points is a list
            return self.entry_points[0]
        self.log.log_warn(
            "perform_get_entry_point: No entry point defined. Defaulting to 0."
        )
        return 0

    def perform_get_length(self) -> int:
        if (
            self._max_virtual_address == 0
            and self._min_virtual_address == 0xFFFFFFFFFFFFFFFF
        ):
            self.log.log_warn(
                "perform_get_length: No segments defined or min/max VA not updated. Returning 0."
            )
            return 0  # No segments, or they were all zero-sized
        length = self._max_virtual_address - self._min_virtual_address
        self.log.log_debug(
            f"perform_get_length: Calculated VA space length: 0x{length:x}"
        )
        return length

    def perform_get_start(self) -> int:
        if self._min_virtual_address == 0xFFFFFFFFFFFFFFFF:
            self.log.log_warn(
                "perform_get_start: Min virtual address not set (no segments?). Returning 0."
            )
            return 0
        self.log.log_debug(
            f"perform_get_start: Returning start address: 0x{self._min_virtual_address:x}"
        )
        return self._min_virtual_address

    def perform_is_executable(self) -> bool:
        return True

    def perform_is_relocatable(self) -> bool:
        return False

    def perform_read(self, addr: int, length: int) -> bytes | None:
        # self.log.log_debug(f"perform_read: VA=0x{addr:x}, Length=0x{length:x}")
        for seg in self.segments:  # self.segments is provided by BinaryView base
            if seg.start <= addr < seg.end:
                offset_in_segment = addr - seg.start
                actual_length = length
                if addr + length > seg.end:
                    actual_length = seg.end - addr
                    # self.log.log_debug(f"  Read truncated to segment end: NewLength=0x{actual_length:x}")

                if actual_length <= 0:
                    return b""

                file_addr = seg.data_offset + offset_in_segment

                # ensure read is within the segment's backing data from file
                if offset_in_segment + actual_length > seg.data_length:
                    # self.log.log_debug(f"  Read (VA 0x{addr:x}) extends beyond segment's file backing (FileOffset 0x{file_addr:x}, SegDataLen 0x{seg.data_length:x}).")
                    available_from_backing = seg.data_length - offset_in_segment
                    if available_from_backing <= 0:
                        # self.log.log_debug(f"  No data available from backing for this part of segment.")
                        return b""  # trying to read part of segment not backed by file data
                    actual_length = available_from_backing
                    # self.log.log_debug(f"  Adjusted read length from backing: 0x{actual_length:x}")

                if actual_length <= 0:
                    return b""

                try:
                    # self.log.log_debug(f"  Reading from raw_data: FileOffset=0x{file_addr:x}, ActualLength=0x{actual_length:x}")
                    return self.raw_data.read(file_addr, actual_length)
                except Exception as e:
                    self.log.log_error(
                        f"Error in perform_read from raw_data at file offset 0x{file_addr:x}: {e}"
                    )
                    return None
        # self.log.log_debug(f"perform_read: No segment contains VA 0x{addr:x}.")
        return None

MinidumpView.register()
